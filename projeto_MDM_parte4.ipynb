{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\Java\\Workspace_Python\\py311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout, Bidirectional, SimpleRNN, MaxPooling1D, Conv1D\n",
    "from keras.optimizers import RMSprop, Nadam\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras import regularizers\n",
    "from keras import backend as K\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import  classification_report\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "\n",
    "def f1score(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2 * ((precision * recall) / (precision + recall + K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix,accuracy_score\n",
    "\n",
    "def imprimir_metricas(precisao, revocacao, f1, acuracia):\n",
    "    precisao = precisao * 100\n",
    "    revocacao = revocacao * 100\n",
    "    f1 = f1 * 100\n",
    "    acuracia = acuracia * 100\n",
    "    print('precisao {:.2f}'.format(precisao))\n",
    "    print('revocacao {:.2f}'.format(revocacao))\n",
    "    print('f1-score {:.2f}'.format(f1))\n",
    "    print('acuracia {:.2f}'.format(acuracia))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_SimpleRNN():\n",
    "    model = Sequential()\n",
    "    model.add(SimpleRNN(units=40))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(units=1, activation='sigmoid'))\n",
    "    return model\n",
    "    \n",
    "def model_LSTM():\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=300, activation='sigmoid', return_sequences=False))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(units=1, activation='sigmoid'))\n",
    "    return model\n",
    "\n",
    "def model_Bidirectional():\n",
    "    model = Sequential()\n",
    "    model.add(Bidirectional(LSTM(units=300, activation='sigmoid', return_sequences=False)))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    return model\n",
    "\n",
    "def model_CNN_LSTM():\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Convolutional Layer\n",
    "    model.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Dropout(0.5))\n",
    "    # LSTM Layer\n",
    "    model.add(LSTM(units=300, activation='sigmoid', return_sequences=False))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotGraph_models(model):\n",
    "    history = model.history\n",
    "\n",
    "    print(history.history.keys())\n",
    "\n",
    "    acc = history.history['acc']\n",
    "    val_acc = history.history['val_acc']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    epochs = range(1, len(acc) + 1)\n",
    "\n",
    "\n",
    "    plt.plot(epochs, acc, 'bo', label = 'Training Accuracy')\n",
    "    plt.plot(epochs, val_acc, 'r', label = 'Validation Accuracy')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    y_arrow = max(val_acc)\n",
    "    x_arrow = val_acc.index(y_arrow) + 1\n",
    "    plt.annotate(str(y_arrow)[:6],\n",
    "                (x_arrow, y_arrow),\n",
    "                xytext=(x_arrow + 5, y_arrow + .02),\n",
    "                arrowprops=dict(facecolor='orange', shrink=0.05))\n",
    "    plt.xticks(epochs)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(epochs, loss, 'bo', label = 'Training Loss')\n",
    "    plt.plot(epochs, val_loss, 'r', label = 'Validation Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.xticks(epochs)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss', patience=3)\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\Java\\Workspace_Python\\py311\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "periodo = 'pre-pandemia'\n",
    "\n",
    "choq = ['volumeTweets_media', 'volumeTweets_variancia', 'volumeTweets_mediaMovelPonterada', 'volumeTweets_entropia', \n",
    " 'indiceInsonia_mediaMovelPonterada', 'indiceInsonia_entropia', \n",
    " 'pronome1Pessoa_media', 'pronome1Pessoa_variancia', 'pronome1Pessoa_mediaMovelPonterada', 'pronome1Pessoa_entropia', \n",
    " 'pronome2Pessoa_mediaMovelPonterada', \n",
    " 'pronome3Pessoa_variancia', 'pronome3Pessoa_mediaMovelPonterada', 'pronome3Pessoa_entropia', \n",
    " 'valencia_variancia', 'valencia_entropia', \n",
    " 'ativacao_variancia', 'ativacao_entropia', \n",
    " 'termosDepressivos_mediaMovelPonterada', \n",
    " 'grafoSocial_variancia', 'grafoSocial_mediaMovelPonterada', 'grafoSocial_entropia',\n",
    " 'medicamentosAntiDepressivo_variancia'\n",
    " ]\n",
    "\n",
    "\n",
    "atributos_anterioes = ['caracteresOrientais_variancia', \n",
    " 'emojis_mediaMovelPonterada', \n",
    " 'curtidas_media', 'curtidas_variancia', 'curtidas_mediaMovelPonterada',\n",
    " 'midia_variancia',\n",
    " 'links_entropia',\n",
    " ]\n",
    "\n",
    "atributos_novos = ['hashtags_variancia', 'hashtags_mediaMovelPonterada', \n",
    "                   'retweets_media', 'retweets_variancia', 'retweets_mediaMovelPonterada', \n",
    " 'mencoes_media', 'mencoes_variancia', 'mencoes_mediaMovelPonterada', \n",
    " 'polaridade_entropia', \n",
    " 'subjetividade_entropia']\n",
    "\n",
    "df = pd.read_csv(f'datasets/twitterbase_{periodo}.csv', sep=';')\n",
    "\n",
    "cv = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "zscore = StandardScaler()\n",
    "\n",
    "train_ratio = 0.70\n",
    "validation_ratio = 0.15\n",
    "test_ratio = 0.15\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "df['classe'] = label_encoder.fit_transform(df['classe']).astype('float64')\n",
    "\n",
    "df1 = df[choq + ['classe']].copy()\n",
    "df2 = df[choq + atributos_anterioes + ['classe']].copy()\n",
    "df3 = df[choq + atributos_novos + ['classe']].copy()\n",
    "\n",
    "x1 = df1.drop('classe', axis=1).copy()\n",
    "y1 = df1['classe'].copy()\n",
    "x1 = zscore.fit_transform(x1)\n",
    "\n",
    "x2 = df2.drop('classe', axis=1).copy()\n",
    "y2 = df2['classe'].copy()\n",
    "x2 = zscore.fit_transform(x2)\n",
    "\n",
    "x3 = df3.drop('classe', axis=1).copy()\n",
    "y3 = df3['classe'].copy()\n",
    "x3 = zscore.fit_transform(x3)\n",
    "\n",
    "model1 = model_SimpleRNN()\n",
    "model2 = model_LSTM()\n",
    "model3 = model_Bidirectional()\n",
    "model4 = model_CNN_LSTM()\n",
    "\n",
    "x4 = df.drop('classe', axis=1).copy()\n",
    "y4 = df['classe'].copy()\n",
    "x4 = zscore.fit_transform(x4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulação 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(x1, y1, test_size=validation_ratio, random_state=42)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_train, y_train, test_size=test_ratio, random_state=42)\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], x_train.shape[1], 1)\n",
    "x_val = x_val.reshape(x_val.shape[0], x_val.shape[1], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\Java\\Workspace_Python\\py311\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From d:\\Java\\Workspace_Python\\py311\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From d:\\Java\\Workspace_Python\\py311\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "\n",
      "SimpleRNN\n",
      "precisao 75.54\n",
      "revocacao 75.68\n",
      "f1-score 75.01\n",
      "acuracia 74.23\n"
     ]
    }
   ],
   "source": [
    "model1.compile(loss='binary_crossentropy', optimizer='nadam', metrics=['acc', f1score, precision_m, recall_m])\n",
    "model1.fit(x_train, y_train,  validation_data=(x_val, y_val),  epochs = epochs, batch_size = 128, shuffle=True, callbacks = [early_stop], verbose=0)\n",
    "loss, acuracia, f1_score, precisao, revocacao = model1.evaluate(x_val, y_val, verbose=0)\n",
    "\n",
    "print()\n",
    "print('SimpleRNN')\n",
    "imprimir_metricas(precisao, revocacao, f1_score, acuracia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LSTM\n",
      "precisao 72.38\n",
      "revocacao 81.74\n",
      "f1-score 76.30\n",
      "acuracia 74.01\n"
     ]
    }
   ],
   "source": [
    "model2.compile(loss='binary_crossentropy', optimizer='nadam', metrics=['acc', f1score, precision_m, recall_m])\n",
    "model2.fit(x_train, y_train,  validation_data=(x_val, y_val),  epochs = epochs, batch_size = 128, shuffle=True, callbacks = [early_stop], verbose=0)\n",
    "loss, acuracia, f1_score, precisao, revocacao = model2.evaluate(x_val, y_val, verbose=0)\n",
    "\n",
    "print()\n",
    "print('LSTM')\n",
    "imprimir_metricas(precisao, revocacao, f1_score, acuracia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LSTM Biredicional\n",
      "precisao 76.71\n",
      "revocacao 69.58\n",
      "f1-score 72.40\n",
      "acuracia 72.89\n"
     ]
    }
   ],
   "source": [
    "model3.compile(loss='binary_crossentropy', optimizer='nadam', metrics=['acc', f1score, precision_m, recall_m])\n",
    "model3.fit(x_train, y_train,  validation_data=(x_val, y_val),  epochs = epochs, batch_size = 128, shuffle=True, callbacks = [early_stop], verbose=0)\n",
    "loss, acuracia, f1_score, precisao, revocacao = model3.evaluate(x_val, y_val, verbose=0)\n",
    "\n",
    "print()\n",
    "print('LSTM Biredicional')\n",
    "imprimir_metricas(precisao, revocacao, f1_score, acuracia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\Java\\Workspace_Python\\py311\\Lib\\site-packages\\keras\\src\\backend.py:6642: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "\n",
      "LSTM + CNN\n",
      "precisao 73.89\n",
      "revocacao 78.54\n",
      "f1-score 75.61\n",
      "acuracia 74.10\n"
     ]
    }
   ],
   "source": [
    "model4.compile(loss='binary_crossentropy', optimizer='nadam', metrics=['acc', f1score, precision_m, recall_m])\n",
    "model4.fit(x_train, y_train,  validation_data=(x_val, y_val),  epochs = epochs, batch_size = 128, shuffle=True, callbacks = [early_stop], verbose=0)\n",
    "loss, acuracia, f1_score, precisao, revocacao = model4.evaluate(x_val, y_val, verbose=0)\n",
    "\n",
    "print()\n",
    "print('LSTM + CNN')\n",
    "imprimir_metricas(precisao, revocacao, f1_score, acuracia)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulação 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(x2, y2, test_size=validation_ratio, random_state=42)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_train, y_train, test_size=test_ratio, random_state=42)\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], x_train.shape[1], 1)\n",
    "x_val = x_val.reshape(x_val.shape[0], x_val.shape[1], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SimpleRNN\n",
      "precisao 75.79\n",
      "revocacao 76.24\n",
      "f1-score 75.44\n",
      "acuracia 74.71\n"
     ]
    }
   ],
   "source": [
    "model1.compile(loss='binary_crossentropy', optimizer='nadam', metrics=['acc', f1score, precision_m, recall_m])\n",
    "model1.fit(x_train, y_train,  validation_data=(x_val, y_val),  epochs = epochs, batch_size = 128, shuffle=True, callbacks = [early_stop], verbose=0)\n",
    "loss, acuracia, f1_score, precisao, revocacao = model1.evaluate(x_val, y_val, verbose=0)\n",
    "\n",
    "print()\n",
    "print('SimpleRNN')\n",
    "imprimir_metricas(precisao, revocacao, f1_score, acuracia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LSTM\n",
      "precisao 75.36\n",
      "revocacao 72.34\n",
      "f1-score 73.25\n",
      "acuracia 72.99\n"
     ]
    }
   ],
   "source": [
    "model2.compile(loss='binary_crossentropy', optimizer='nadam', metrics=['acc', f1score, precision_m, recall_m])\n",
    "model2.fit(x_train, y_train,  validation_data=(x_val, y_val),  epochs = epochs, batch_size = 128, shuffle=True, callbacks = [early_stop], verbose=0)\n",
    "loss, acuracia, f1_score, precisao, revocacao = model2.evaluate(x_val, y_val, verbose=0)\n",
    "\n",
    "print()\n",
    "print('LSTM')\n",
    "imprimir_metricas(precisao, revocacao, f1_score, acuracia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LSTM Biredicional\n",
      "precisao 75.56\n",
      "revocacao 77.13\n",
      "f1-score 75.81\n",
      "acuracia 74.84\n"
     ]
    }
   ],
   "source": [
    "model3.compile(loss='binary_crossentropy', optimizer='nadam', metrics=['acc', f1score, precision_m, recall_m])\n",
    "model3.fit(x_train, y_train,  validation_data=(x_val, y_val),  epochs = epochs, batch_size = 128, shuffle=True, callbacks = [early_stop], verbose=0)\n",
    "loss, acuracia, f1_score, precisao, revocacao = model3.evaluate(x_val, y_val, verbose=0)\n",
    "\n",
    "print()\n",
    "print('LSTM Biredicional')\n",
    "imprimir_metricas(precisao, revocacao, f1_score, acuracia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LSTM + CNN\n",
      "precisao 67.41\n",
      "revocacao 95.19\n",
      "f1-score 78.51\n",
      "acuracia 73.18\n"
     ]
    }
   ],
   "source": [
    "model4.compile(loss='binary_crossentropy', optimizer='nadam', metrics=['acc', f1score, precision_m, recall_m])\n",
    "model4.fit(x_train, y_train,  validation_data=(x_val, y_val),  epochs = epochs, batch_size = 128, shuffle=True, callbacks = [early_stop], verbose=0)\n",
    "loss, acuracia, f1_score, precisao, revocacao = model4.evaluate(x_val, y_val, verbose=0)\n",
    "\n",
    "print()\n",
    "print('LSTM + CNN')\n",
    "imprimir_metricas(precisao, revocacao, f1_score, acuracia)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulação 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(x3, y3, test_size=validation_ratio, random_state=42)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_train, y_train, test_size=test_ratio, random_state=42)\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], x_train.shape[1], 1)\n",
    "x_val = x_val.reshape(x_val.shape[0], x_val.shape[1], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SimpleRNN\n",
      "precisao 71.18\n",
      "revocacao 90.30\n",
      "f1-score 79.19\n",
      "acuracia 75.55\n"
     ]
    }
   ],
   "source": [
    "model1.compile(loss='binary_crossentropy', optimizer='nadam', metrics=['acc', f1score, precision_m, recall_m])\n",
    "model1.fit(x_train, y_train,  validation_data=(x_val, y_val),  epochs = epochs, batch_size = 128, shuffle=True, callbacks = [early_stop], verbose=0)\n",
    "loss, acuracia, f1_score, precisao, revocacao = model1.evaluate(x_val, y_val, verbose=0)\n",
    "\n",
    "print()\n",
    "print('SimpleRNN')\n",
    "imprimir_metricas(precisao, revocacao, f1_score, acuracia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LSTM\n",
      "precisao 75.43\n",
      "revocacao 79.52\n",
      "f1-score 76.90\n",
      "acuracia 75.62\n"
     ]
    }
   ],
   "source": [
    "model2.compile(loss='binary_crossentropy', optimizer='nadam', metrics=['acc', f1score, precision_m, recall_m])\n",
    "model2.fit(x_train, y_train,  validation_data=(x_val, y_val),  epochs = epochs, batch_size = 128, shuffle=True, callbacks = [early_stop], verbose=0)\n",
    "loss, acuracia, f1_score, precisao, revocacao = model2.evaluate(x_val, y_val, verbose=0)\n",
    "\n",
    "print()\n",
    "print('LSTM')\n",
    "imprimir_metricas(precisao, revocacao, f1_score, acuracia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LSTM Biredicional\n",
      "precisao 69.12\n",
      "revocacao 93.27\n",
      "f1-score 78.98\n",
      "acuracia 74.52\n"
     ]
    }
   ],
   "source": [
    "model3.compile(loss='binary_crossentropy', optimizer='nadam', metrics=['acc', f1score, precision_m, recall_m])\n",
    "model3.fit(x_train, y_train,  validation_data=(x_val, y_val),  epochs = epochs, batch_size = 128, shuffle=True, callbacks = [early_stop], verbose=0)\n",
    "loss, acuracia, f1_score, precisao, revocacao = model3.evaluate(x_val, y_val, verbose=0)\n",
    "\n",
    "print()\n",
    "print('LSTM Biredicional')\n",
    "imprimir_metricas(precisao, revocacao, f1_score, acuracia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LSTM + CNN\n",
      "precisao 69.26\n",
      "revocacao 93.10\n",
      "f1-score 79.02\n",
      "acuracia 74.57\n"
     ]
    }
   ],
   "source": [
    "model4.compile(loss='binary_crossentropy', optimizer='nadam', metrics=['acc', f1score, precision_m, recall_m])\n",
    "model4.fit(x_train, y_train,  validation_data=(x_val, y_val),  epochs = epochs, batch_size = 128, shuffle=True, callbacks = [early_stop], verbose=0)\n",
    "loss, acuracia, f1_score, precisao, revocacao = model4.evaluate(x_val, y_val, verbose=0)\n",
    "\n",
    "print()\n",
    "print('LSTM + CNN')\n",
    "imprimir_metricas(precisao, revocacao, f1_score, acuracia)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulação 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(x4, y4, test_size=validation_ratio, random_state=42)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_train, y_train, test_size=test_ratio, random_state=42)\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], x_train.shape[1], 1)\n",
    "x_val = x_val.reshape(x_val.shape[0], x_val.shape[1], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SimpleRNN\n",
      "precisao 67.65\n",
      "revocacao 93.75\n",
      "f1-score 78.16\n",
      "acuracia 73.02\n"
     ]
    }
   ],
   "source": [
    "model1.compile(loss='binary_crossentropy', optimizer='nadam', metrics=['acc', f1score, precision_m, recall_m])\n",
    "model1.fit(x_train, y_train,  validation_data=(x_val, y_val),  epochs = epochs, batch_size = 128, shuffle=True, callbacks = [early_stop], verbose=0)\n",
    "loss, acuracia, f1_score, precisao, revocacao = model1.evaluate(x_val, y_val, verbose=0)\n",
    "\n",
    "print()\n",
    "print('SimpleRNN')\n",
    "imprimir_metricas(precisao, revocacao, f1_score, acuracia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LSTM\n",
      "precisao 63.14\n",
      "revocacao 97.00\n",
      "f1-score 76.09\n",
      "acuracia 68.60\n"
     ]
    }
   ],
   "source": [
    "model2.compile(loss='binary_crossentropy', optimizer='nadam', metrics=['acc', f1score, precision_m, recall_m])\n",
    "model2.fit(x_train, y_train,  validation_data=(x_val, y_val),  epochs = epochs, batch_size = 128, shuffle=True, callbacks = [early_stop], verbose=0)\n",
    "loss, acuracia, f1_score, precisao, revocacao = model2.evaluate(x_val, y_val, verbose=0)\n",
    "\n",
    "print()\n",
    "print('LSTM')\n",
    "imprimir_metricas(precisao, revocacao, f1_score, acuracia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LSTM Biredicional\n",
      "precisao 69.31\n",
      "revocacao 93.54\n",
      "f1-score 79.20\n",
      "acuracia 74.76\n"
     ]
    }
   ],
   "source": [
    "model3.compile(loss='binary_crossentropy', optimizer='nadam', metrics=['acc', f1score, precision_m, recall_m])\n",
    "model3.fit(x_train, y_train,  validation_data=(x_val, y_val),  epochs = epochs, batch_size = 128, shuffle=True, callbacks = [early_stop], verbose=0)\n",
    "loss, acuracia, f1_score, precisao, revocacao = model3.evaluate(x_val, y_val, verbose=0)\n",
    "\n",
    "print()\n",
    "print('LSTM Biredicional')\n",
    "imprimir_metricas(precisao, revocacao, f1_score, acuracia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LSTM + CNN\n",
      "precisao 73.44\n",
      "revocacao 85.42\n",
      "f1-score 78.55\n",
      "acuracia 76.05\n"
     ]
    }
   ],
   "source": [
    "model4.compile(loss='binary_crossentropy', optimizer='nadam', metrics=['acc', f1score, precision_m, recall_m])\n",
    "model4.fit(x_train, y_train,  validation_data=(x_val, y_val),  epochs = epochs, batch_size = 128, shuffle=True, callbacks = [early_stop], verbose=0)\n",
    "loss, acuracia, f1_score, precisao, revocacao = model4.evaluate(x_val, y_val, verbose=0)\n",
    "\n",
    "print()\n",
    "print('LSTM + CNN')\n",
    "imprimir_metricas(precisao, revocacao, f1_score, acuracia)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandemia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "periodo = 'pandemia'\n",
    "\n",
    "choq = ['volumeTweets_media', 'volumeTweets_variancia', 'volumeTweets_mediaMovelPonterada', 'volumeTweets_entropia', \n",
    "'indiceInsonia_variancia', 'indiceInsonia_mediaMovelPonterada', 'indiceInsonia_entropia', \n",
    "'pronome1Pessoa_media', 'pronome1Pessoa_variancia', 'pronome1Pessoa_mediaMovelPonterada', 'pronome1Pessoa_entropia', \n",
    "'pronome2Pessoa_mediaMovelPonterada', \n",
    "'pronome3Pessoa_media', 'pronome3Pessoa_variancia', 'pronome3Pessoa_mediaMovelPonterada', 'pronome3Pessoa_entropia', \n",
    "'valencia_mediaMovelPonterada', 'valencia_entropia', \n",
    "'ativacao_mediaMovelPonterada', 'ativacao_entropia', \n",
    "'termosDepressivos_variancia', \n",
    "'grafoSocial_variancia', 'grafoSocial_mediaMovelPonterada', 'grafoSocial_entropia',\n",
    "'medicamentosAntiDepressivo_mediaMovelPonterada'\n",
    "]\n",
    "\n",
    "\n",
    "atributos_anterioes = ['caracteresOrientais_variancia', \n",
    "'emojis_variancia', \n",
    "'midia_variancia', 'midia_mediaMovelPonterada', \n",
    "'curtidas_media', 'curtidas_variancia', 'curtidas_mediaMovelPonterada',\n",
    "'links_mediaMovelPonterada'\n",
    "]\n",
    "\n",
    "atributos_novos = ['hashtags_variancia', 'hashtags_mediaMovelPonterada', \n",
    "'retweets_variancia', \n",
    "'mencoes_variancia', 'mencoes_mediaMovelPonterada', \n",
    "'polaridade_entropia', \n",
    "'subjetividade_entropia'\n",
    "]\n",
    "\n",
    "df = pd.read_csv(f'datasets/twitterbase_{periodo}.csv', sep=';')\n",
    "\n",
    "cv = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "zscore = StandardScaler()\n",
    "\n",
    "train_ratio = 0.70\n",
    "validation_ratio = 0.15\n",
    "test_ratio = 0.15\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "df['classe'] = label_encoder.fit_transform(df['classe']).astype('float64')\n",
    "\n",
    "df1 = df[choq + ['classe']].copy()\n",
    "df2 = df[choq + atributos_anterioes + ['classe']].copy()\n",
    "df3 = df[choq + atributos_novos + ['classe']].copy()\n",
    "\n",
    "x1 = df1.drop('classe', axis=1).copy()\n",
    "y1 = df1['classe'].copy()\n",
    "x1 = zscore.fit_transform(x1)\n",
    "\n",
    "x2 = df2.drop('classe', axis=1).copy()\n",
    "y2 = df2['classe'].copy()\n",
    "x2 = zscore.fit_transform(x2)\n",
    "\n",
    "x3 = df3.drop('classe', axis=1).copy()\n",
    "y3 = df3['classe'].copy()\n",
    "x3 = zscore.fit_transform(x3)\n",
    "\n",
    "model1 = model_SimpleRNN()\n",
    "model2 = model_LSTM()\n",
    "model3 = model_Bidirectional()\n",
    "model4 = model_CNN_LSTM()\n",
    "\n",
    "x4 = df.drop('classe', axis=1).copy()\n",
    "y4 = df['classe'].copy()\n",
    "x4 = zscore.fit_transform(x4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulação 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(x1, y1, test_size=validation_ratio, random_state=42)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_train, y_train, test_size=test_ratio, random_state=42)\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], x_train.shape[1], 1)\n",
    "x_val = x_val.reshape(x_val.shape[0], x_val.shape[1], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SimpleRNN\n",
      "precisao 76.11\n",
      "revocacao 73.25\n",
      "f1-score 74.02\n",
      "acuracia 74.02\n"
     ]
    }
   ],
   "source": [
    "model1.compile(loss='binary_crossentropy', optimizer='nadam', metrics=['acc', f1score, precision_m, recall_m])\n",
    "model1.fit(x_train, y_train,  validation_data=(x_val, y_val),  epochs = epochs, batch_size = 128, shuffle=True, callbacks = [early_stop], verbose=0)\n",
    "loss, acuracia, f1_score, precisao, revocacao = model1.evaluate(x_val, y_val, verbose=0)\n",
    "\n",
    "print()\n",
    "print('SimpleRNN')\n",
    "imprimir_metricas(precisao, revocacao, f1_score, acuracia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LSTM\n",
      "precisao 64.81\n",
      "revocacao 94.36\n",
      "f1-score 76.46\n",
      "acuracia 70.52\n"
     ]
    }
   ],
   "source": [
    "model2.compile(loss='binary_crossentropy', optimizer='nadam', metrics=['acc', f1score, precision_m, recall_m])\n",
    "model2.fit(x_train, y_train,  validation_data=(x_val, y_val),  epochs = epochs, batch_size = 128, shuffle=True, callbacks = [early_stop], verbose=0)\n",
    "loss, acuracia, f1_score, precisao, revocacao = model2.evaluate(x_val, y_val, verbose=0)\n",
    "\n",
    "print()\n",
    "print('LSTM')\n",
    "imprimir_metricas(precisao, revocacao, f1_score, acuracia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LSTM Biredicional\n",
      "precisao 70.98\n",
      "revocacao 86.97\n",
      "f1-score 77.72\n",
      "acuracia 74.73\n"
     ]
    }
   ],
   "source": [
    "model3.compile(loss='binary_crossentropy', optimizer='nadam', metrics=['acc', f1score, precision_m, recall_m])\n",
    "model3.fit(x_train, y_train,  validation_data=(x_val, y_val),  epochs = epochs, batch_size = 128, shuffle=True, callbacks = [early_stop], verbose=0)\n",
    "loss, acuracia, f1_score, precisao, revocacao = model3.evaluate(x_val, y_val, verbose=0)\n",
    "\n",
    "print()\n",
    "print('LSTM Biredicional')\n",
    "imprimir_metricas(precisao, revocacao, f1_score, acuracia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LSTM + CNN\n",
      "precisao 70.87\n",
      "revocacao 85.99\n",
      "f1-score 77.22\n",
      "acuracia 74.31\n"
     ]
    }
   ],
   "source": [
    "model4.compile(loss='binary_crossentropy', optimizer='nadam', metrics=['acc', f1score, precision_m, recall_m])\n",
    "model4.fit(x_train, y_train,  validation_data=(x_val, y_val),  epochs = epochs, batch_size = 128, shuffle=True, callbacks = [early_stop], verbose=0)\n",
    "loss, acuracia, f1_score, precisao, revocacao = model4.evaluate(x_val, y_val, verbose=0)\n",
    "\n",
    "print()\n",
    "print('LSTM + CNN')\n",
    "imprimir_metricas(precisao, revocacao, f1_score, acuracia)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulação 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(x2, y2, test_size=validation_ratio, random_state=42)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_train, y_train, test_size=test_ratio, random_state=42)\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], x_train.shape[1], 1)\n",
    "x_val = x_val.reshape(x_val.shape[0], x_val.shape[1], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SimpleRNN\n",
      "precisao 76.24\n",
      "revocacao 76.40\n",
      "f1-score 75.70\n",
      "acuracia 75.14\n"
     ]
    }
   ],
   "source": [
    "model1.compile(loss='binary_crossentropy', optimizer='nadam', metrics=['acc', f1score, precision_m, recall_m])\n",
    "model1.fit(x_train, y_train,  validation_data=(x_val, y_val),  epochs = epochs, batch_size = 128, shuffle=True, callbacks = [early_stop], verbose=0)\n",
    "loss, acuracia, f1_score, precisao, revocacao = model1.evaluate(x_val, y_val, verbose=0)\n",
    "\n",
    "print()\n",
    "print('SimpleRNN')\n",
    "imprimir_metricas(precisao, revocacao, f1_score, acuracia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LSTM\n",
      "precisao 75.80\n",
      "revocacao 65.24\n",
      "f1-score 69.33\n",
      "acuracia 71.00\n"
     ]
    }
   ],
   "source": [
    "model2.compile(loss='binary_crossentropy', optimizer='nadam', metrics=['acc', f1score, precision_m, recall_m])\n",
    "model2.fit(x_train, y_train,  validation_data=(x_val, y_val),  epochs = epochs, batch_size = 128, shuffle=True, callbacks = [early_stop], verbose=0)\n",
    "loss, acuracia, f1_score, precisao, revocacao = model2.evaluate(x_val, y_val, verbose=0)\n",
    "\n",
    "print()\n",
    "print('LSTM')\n",
    "imprimir_metricas(precisao, revocacao, f1_score, acuracia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LSTM Biredicional\n",
      "precisao 70.93\n",
      "revocacao 87.10\n",
      "f1-score 77.76\n",
      "acuracia 74.73\n"
     ]
    }
   ],
   "source": [
    "model3.compile(loss='binary_crossentropy', optimizer='nadam', metrics=['acc', f1score, precision_m, recall_m])\n",
    "model3.fit(x_train, y_train,  validation_data=(x_val, y_val),  epochs = epochs, batch_size = 128, shuffle=True, callbacks = [early_stop], verbose=0)\n",
    "loss, acuracia, f1_score, precisao, revocacao = model3.evaluate(x_val, y_val, verbose=0)\n",
    "\n",
    "print()\n",
    "print('LSTM Biredicional')\n",
    "imprimir_metricas(precisao, revocacao, f1_score, acuracia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LSTM + CNN\n",
      "precisao 69.17\n",
      "revocacao 90.22\n",
      "f1-score 77.88\n",
      "acuracia 74.00\n"
     ]
    }
   ],
   "source": [
    "model4.compile(loss='binary_crossentropy', optimizer='nadam', metrics=['acc', f1score, precision_m, recall_m])\n",
    "model4.fit(x_train, y_train,  validation_data=(x_val, y_val),  epochs = epochs, batch_size = 128, shuffle=True, callbacks = [early_stop], verbose=0)\n",
    "loss, acuracia, f1_score, precisao, revocacao = model4.evaluate(x_val, y_val, verbose=0)\n",
    "\n",
    "print()\n",
    "print('LSTM + CNN')\n",
    "imprimir_metricas(precisao, revocacao, f1_score, acuracia)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulação 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(x3, y3, test_size=validation_ratio, random_state=42)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_train, y_train, test_size=test_ratio, random_state=42)\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], x_train.shape[1], 1)\n",
    "x_val = x_val.reshape(x_val.shape[0], x_val.shape[1], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SimpleRNN\n",
      "precisao 75.86\n",
      "revocacao 78.44\n",
      "f1-score 76.59\n",
      "acuracia 75.71\n"
     ]
    }
   ],
   "source": [
    "model1.compile(loss='binary_crossentropy', optimizer='nadam', metrics=['acc', f1score, precision_m, recall_m])\n",
    "model1.fit(x_train, y_train,  validation_data=(x_val, y_val),  epochs = epochs, batch_size = 128, shuffle=True, callbacks = [early_stop], verbose=0)\n",
    "loss, acuracia, f1_score, precisao, revocacao = model1.evaluate(x_val, y_val, verbose=0)\n",
    "\n",
    "print()\n",
    "print('SimpleRNN')\n",
    "imprimir_metricas(precisao, revocacao, f1_score, acuracia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LSTM\n",
      "precisao 68.27\n",
      "revocacao 91.73\n",
      "f1-score 77.81\n",
      "acuracia 73.44\n"
     ]
    }
   ],
   "source": [
    "model2.compile(loss='binary_crossentropy', optimizer='nadam', metrics=['acc', f1score, precision_m, recall_m])\n",
    "model2.fit(x_train, y_train,  validation_data=(x_val, y_val),  epochs = epochs, batch_size = 128, shuffle=True, callbacks = [early_stop], verbose=0)\n",
    "loss, acuracia, f1_score, precisao, revocacao = model2.evaluate(x_val, y_val, verbose=0)\n",
    "\n",
    "print()\n",
    "print('LSTM')\n",
    "imprimir_metricas(precisao, revocacao, f1_score, acuracia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LSTM Biredicional\n",
      "precisao 72.32\n",
      "revocacao 84.05\n",
      "f1-score 77.26\n",
      "acuracia 74.93\n"
     ]
    }
   ],
   "source": [
    "model3.compile(loss='binary_crossentropy', optimizer='nadam', metrics=['acc', f1score, precision_m, recall_m])\n",
    "model3.fit(x_train, y_train,  validation_data=(x_val, y_val),  epochs = epochs, batch_size = 128, shuffle=True, callbacks = [early_stop], verbose=0)\n",
    "loss, acuracia, f1_score, precisao, revocacao = model3.evaluate(x_val, y_val, verbose=0)\n",
    "\n",
    "print()\n",
    "print('LSTM Biredicional')\n",
    "imprimir_metricas(precisao, revocacao, f1_score, acuracia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LSTM + CNN\n",
      "precisao 72.34\n",
      "revocacao 87.00\n",
      "f1-score 78.53\n",
      "acuracia 75.85\n"
     ]
    }
   ],
   "source": [
    "model4.compile(loss='binary_crossentropy', optimizer='nadam', metrics=['acc', f1score, precision_m, recall_m])\n",
    "model4.fit(x_train, y_train,  validation_data=(x_val, y_val),  epochs = epochs, batch_size = 128, shuffle=True, callbacks = [early_stop], verbose=0)\n",
    "loss, acuracia, f1_score, precisao, revocacao = model4.evaluate(x_val, y_val, verbose=0)\n",
    "\n",
    "print()\n",
    "print('LSTM + CNN')\n",
    "imprimir_metricas(precisao, revocacao, f1_score, acuracia)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulação 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(x4, y4, test_size=validation_ratio, random_state=42)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_train, y_train, test_size=test_ratio, random_state=42)\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], x_train.shape[1], 1)\n",
    "x_val = x_val.reshape(x_val.shape[0], x_val.shape[1], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SimpleRNN\n",
      "precisao 67.60\n",
      "revocacao 91.51\n",
      "f1-score 77.36\n",
      "acuracia 72.84\n"
     ]
    }
   ],
   "source": [
    "model1.compile(loss='binary_crossentropy', optimizer='nadam', metrics=['acc', f1score, precision_m, recall_m])\n",
    "model1.fit(x_train, y_train,  validation_data=(x_val, y_val),  epochs = epochs, batch_size = 128, shuffle=True, callbacks = [early_stop], verbose=0)\n",
    "loss, acuracia, f1_score, precisao, revocacao = model1.evaluate(x_val, y_val, verbose=0)\n",
    "\n",
    "print()\n",
    "print('SimpleRNN')\n",
    "imprimir_metricas(precisao, revocacao, f1_score, acuracia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LSTM\n",
      "precisao 79.28\n",
      "revocacao 54.48\n",
      "f1-score 63.65\n",
      "acuracia 68.75\n"
     ]
    }
   ],
   "source": [
    "model2.compile(loss='binary_crossentropy', optimizer='nadam', metrics=['acc', f1score, precision_m, recall_m])\n",
    "model2.fit(x_train, y_train,  validation_data=(x_val, y_val),  epochs = epochs, batch_size = 128, shuffle=True, callbacks = [early_stop], verbose=0)\n",
    "loss, acuracia, f1_score, precisao, revocacao = model2.evaluate(x_val, y_val, verbose=0)\n",
    "\n",
    "print()\n",
    "print('LSTM')\n",
    "imprimir_metricas(precisao, revocacao, f1_score, acuracia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LSTM Biredicional\n",
      "precisao 78.67\n",
      "revocacao 72.58\n",
      "f1-score 74.96\n",
      "acuracia 75.45\n"
     ]
    }
   ],
   "source": [
    "model3.compile(loss='binary_crossentropy', optimizer='nadam', metrics=['acc', f1score, precision_m, recall_m])\n",
    "model3.fit(x_train, y_train,  validation_data=(x_val, y_val),  epochs = epochs, batch_size = 128, shuffle=True, callbacks = [early_stop], verbose=0)\n",
    "loss, acuracia, f1_score, precisao, revocacao = model3.evaluate(x_val, y_val, verbose=0)\n",
    "\n",
    "print()\n",
    "print('LSTM Biredicional')\n",
    "imprimir_metricas(precisao, revocacao, f1_score, acuracia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LSTM + CNN\n",
      "precisao 68.97\n",
      "revocacao 94.14\n",
      "f1-score 79.16\n",
      "acuracia 74.86\n"
     ]
    }
   ],
   "source": [
    "model4.compile(loss='binary_crossentropy', optimizer='nadam', metrics=['acc', f1score, precision_m, recall_m])\n",
    "model4.fit(x_train, y_train,  validation_data=(x_val, y_val),  epochs = epochs, batch_size = 128, shuffle=True, callbacks = [early_stop], verbose=0)\n",
    "loss, acuracia, f1_score, precisao, revocacao = model4.evaluate(x_val, y_val, verbose=0)\n",
    "\n",
    "print()\n",
    "print('LSTM + CNN')\n",
    "imprimir_metricas(precisao, revocacao, f1_score, acuracia)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
